{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as confusion_matrix_skl\n",
    "\n",
    "from dataset import iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.1 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data fitting with outcome that takes on (non-numerical) values like\n",
    "    - true or false\n",
    "    - spam or not spam\n",
    "    - dog, horse, or mouse\n",
    "- outcome values are called *labels* or *categories*\n",
    "\n",
    "*Boolean* or *2-way* classification: outcomes as +1 (true) and −1 (false)\n",
    "- model or *classifier*: $\\hat{y} = \\hat{f}(x),\\ \\text{where}\\ \\hat{f} : \\mathbb{R}^n \\rightarrow \\{−1, +1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2pm1 = lambda b: 2*b-1\n",
    "b = True\n",
    "tf2pm1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([True, False, True])\n",
    "tf2pm1(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data point (x,y), predicted outcome $\\hat{y} = \\hat{f}(x)$\n",
    "- only four possibilities:\n",
    "    - True positive. $y = +1$ and $\\hat{y} = +1$.\n",
    "    - True negative. $y = −1$ and $\\hat{y} = −1$.\n",
    "        (in these two cases, the prediction is correct)\n",
    "    - False positive or type I error. $y = −1$ and $\\hat{y} = +1$.\n",
    "    - False negative or type II error. $y = +1$ and $\\hat{y} = −1$.\n",
    "        (in these two cases, the prediction is wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix or contingency table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- given data set $x(1), \\ldots, x(N)$, $y(1), \\ldots, y(N)$ and classifier $\\hat{f}$\n",
    "- count each of the four outcomes\n",
    "\n",
    "||$\\hat{y} = +1$|$\\hat{y} = −1$|Total|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|y = +1| $N_{tp}$ | $N_{fn}$ | $N_p$ |\n",
    "|y = −1| $N_{fp}$ | $N_{tn}$ | $N_n$ |\n",
    "|All| $N_{tp} + N_{fp}$ | $N_{fn} + N_{tp}$ | $N$ |\n",
    "\n",
    "- off-diagonal terms are prediction errors\n",
    "- many error rates and accuracy measures are used\n",
    "    - error rate is $(N_{fp} + N_{fn})/N$\n",
    "    - true positive (or recall) rate is $N_{tp}/N_{p}$\n",
    "    - false positive rate (or false alarm rate) is $N_{fp}/N_n$ \\\n",
    "    Find more metrics here: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "- a proposed classifier is judged by its error rate(s) on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 18],\n",
       "       [24, 19]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count errors and correct predictions\n",
    "Ntp = lambda y, yhat: sum((y == True) & (yhat == True))\n",
    "Nfn = lambda y, yhat: sum((y == True) & (yhat == False))\n",
    "Nfp = lambda y, yhat: sum((y == False) & (yhat == True))\n",
    "Ntn = lambda y, yhat: sum((y == False) & (yhat == False))\n",
    "\n",
    "error_rate = lambda y, yhat: (Nfn(y, yhat) + Nfp(y,yhat)) / len(y)\n",
    "error_rate_compact = lambda y, yhat: np.average(y != yhat)\n",
    "\n",
    "confusion_matrix = lambda y, yhat: np.block([[Ntp(y,yhat), Nfn(y,yhat)], \\\n",
    "                                             [Nfp(y,yhat), Ntn(y,yhat)]])\n",
    "\n",
    "y = np.random.randint(2, size=100)\n",
    "yhat = np.random.randint(2, size = 100)\n",
    "\n",
    "confusion_matrix(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 24],\n",
       "       [18, 39]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.metrics.confusion_matrix\n",
    "# [[Ntn, Nfp\n",
    "#   Nfn, Ntp]]\n",
    "confusion_matrix_skl(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "0.42\n"
     ]
    }
   ],
   "source": [
    "print(error_rate(y, yhat))\n",
    "print(error_rate_compact(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.2 Least squares classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit model $\\tilde{f}$ to encoded $(\\pm 1) y(i)$ values using standard least squares data fitting\n",
    "- $\\tilde{f}(x)$ should be near $+1$ when $y = +1$, and near $−1$ when $y = −1$\n",
    "- $\\tilde{f}(x)$ is a number\n",
    "- use model $\\hat{f}(x) = sign(\\tilde{f}(x))$\n",
    "- (size of $\\tilde{f}(x)$ is related to the 'confidence' in the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression model\n",
    "ftilde = lambda x: x @ beta + v\n",
    "# Regression classifier\n",
    "fhat = lambda x: ftilde(x) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris flower classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.39056373, -0.09175217,  0.40553677,  0.00797582,  1.10355865])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = iris_data()\n",
    "\n",
    "# Create 150 by 4 data matrix\n",
    "iris = np.vstack([D['setosa'], D['versicolor'], D['virginica']])\n",
    "# y[k] is true (1) if virginica, false (-1) otherwise\n",
    "y = np.concatenate([np.zeros(100), np.ones(50)])\n",
    "A = np.column_stack([np.ones(150), iris])\n",
    "\n",
    "theta = np.linalg.lstsq(A, 2*y-1, rcond=None)[0]\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  4],\n",
       "       [ 7, 93]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = A @ theta > 0\n",
    "C = confusion_matrix(y, yhat)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(y != yhat)  # error_rate_compact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.3 Multi-class classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K > 2 possible labels, with label set {1,. . . ,K}\n",
    "- predictor is $\\hat{f} : \\mathbb{R}^n \\rightarrow \\{1, \\ldots, K\\}$\n",
    "- for given predictor and data set, confusion matrix is K × K\n",
    "- some off-diagonal entries may be much worse than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class error rate and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9. 7. 9. 7.]\n",
      " [3. 9. 6. 5.]\n",
      " [5. 8. 7. 5.]\n",
      " [6. 8. 0. 6.]]\n"
     ]
    }
   ],
   "source": [
    "error_rate = lambda y, yhat: np.average(y != yhat)\n",
    "def confusion_matrix(y, yhat, K):\n",
    "    C = np.zeros((K,K))\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            C[i,j] = sum((y == i+1) & (yhat == j+1))\n",
    "    return C\n",
    "\n",
    "# test for K = 4 on random vectors of length 100\n",
    "K = 4\n",
    "y = np.random.randint(1, K+1, size=100)\n",
    "yhat = np.random.randint(1, K+1, size=100)\n",
    "C = confusion_matrix(y, yhat, K)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.69, 0.69)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(y,yhat), 1 - sum(np.diag(C))/np.sum(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares multi-class classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a least squares classifier for each label versus the others (*one-versus-others* or *one-versus-all* classifier)\n",
    "- take as classifier\n",
    "$$\n",
    "\\hat{f}(x) = \\underset{k={1,...,K}}{\\text{argmax}} \\in \\tilde{f}_k(x)\n",
    "$$\n",
    "    where $\\tilde{f}_k = x^T\\theta_k$ is the least squares regression model for label $k$ against the others.\n",
    "    The notation argmax means the index of the largest value among the numbers $\\tilde{f}_k(x)$, for k = 1, . . . , K. (i.e., choose label k with largest value of $\\tilde{f}_k(x)$)\n",
    "\n",
    "- The n-vector $\\theta_1, \\ldots, \\theta_K$ are the coefficients or parameters in the model. We can express this in matrix-vector notation as\n",
    "$$\n",
    "\\hat{f}(x) = \\text{argmax}(x^T \\Theta),\n",
    "$$\n",
    "    where $\\Theta = [\\theta_1 \\ldots \\theta_K]$ is the n × K matrix of model coefficients, and the argmax of a row vector has the obvious meaning.\n",
    "\n",
    "\n",
    "- for example, with\n",
    "\n",
    "$$\n",
    "\\tilde{f}_1(x) = −0.7, \\quad\n",
    "\\tilde{f}_2(x) = +0.2, \\quad\n",
    "\\tilde{f}_3(x) = +0.8\n",
    "$$\n",
    "\n",
    "we choose $\\hat{f}(x) = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32728205,  0.74927263,  0.85829598, -0.26169784, -0.57292648],\n",
       "       [-0.28567832, -1.35986903, -0.12195252, -0.0160003 , -0.21255611],\n",
       "       [-0.14816482,  0.60836306, -0.10287327,  0.68597006, -0.88790113],\n",
       "       [ 0.47383631, -0.43889257,  0.58151237,  0.24587018, -0.40126887]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_argmax = lambda u: np.array([np.argmax(u[i,:]) for i in range(len(u))])\n",
    "A = np.random.normal(size=(4, 5))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_argmax(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a data set with N examples is stored as an n × N data matrix $X$, and Theta is an n × K matrix with the coefficient vectors $\\theta_k$, as its columns, then we can now define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhat = lambda X, Theta: 1 + row_argmax(X.T @ Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to find the N-vector of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use least squares to find the coefficient matrix $\\Theta$ for a multi-class classifier with n features and K classes, from a data set of N examples.\n",
    "-  assume the data is given as an n × N matrix $X$ and an N-vector $y^{cl}$ with entries in {1, . . . , K} that give the classes of the examples.\n",
    "- least squares objective can be expressed as a matrix norm squared,\n",
    "$$\n",
    "\\| X^T \\Theta - Y \\|^2\n",
    "$$\n",
    "where $Y$ is the N × K vector with\n",
    "$$\n",
    "Y_{ij} = \\begin{cases}\n",
    "1 & y^{cl}_i = j \\\\\n",
    "−1 & y^{cl}_i \\ne j\n",
    "\\end{cases}\n",
    "$$\n",
    "- the rows of $Y$ describe the classes using one-hot encoding, converted from 0/1 to −1/ + 1 values\n",
    "- least squares solution is given by $\\Theta = (X^T)^\\dagger Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 0 2 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(ycl, K):\n",
    "    N = len(ycl)\n",
    "    Y = np.zeros((N, K))\n",
    "    for j in range(K):\n",
    "        Y[np.where(ycl == j), j] = 1\n",
    "    return Y\n",
    "K = 4\n",
    "ycl = np.random.randint(K, size = 6)\n",
    "print(ycl)\n",
    "Y = one_hot(ycl ,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1.,  1.],\n",
       "       [-1., -1.,  1., -1.],\n",
       "       [ 1., -1., -1., -1.],\n",
       "       [-1., -1.,  1., -1.],\n",
       "       [-1.,  1., -1., -1.],\n",
       "       [-1.,  1., -1., -1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_multiclass(X, ycl, K):\n",
    "    n, N = X.shape\n",
    "    Theta = np.linalg.lstsq(X.T, 2*one_hot(ycl - 1, K) - 1, rcond=None)[0]\n",
    "    yhat = 1 + row_argmax(X.T @ Theta)\n",
    "    return Theta, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris flower classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "D = iris_data()\n",
    "setosa = np.array(D['setosa'])\n",
    "versicolor = np.array(D['versicolor'])\n",
    "virginica = np.array(D['virginica'])\n",
    "print(setosa.shape)  # (number of samples, number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 18 48 37 16 33 40 39 27 30 19  3 25 22  1 23 13 10 15 21  6 35 26  0\n",
      "  5 11 12  9 43 20 38 29 32 41 14 42 31 45 49 28 24 17 47 36 34 44 46  7\n",
      "  4  8]\n"
     ]
    }
   ],
   "source": [
    "# pick three random permutations of 1,...,50\n",
    "I1 = np.random.permutation(50)\n",
    "I2 = np.random.permutation(50)\n",
    "I3 = np.random.permutation(50)\n",
    "print(I1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 120)\n"
     ]
    }
   ],
   "source": [
    "# training set is 40 randomly picked examples per class\n",
    "Xtrain = np.vstack([setosa[I1[:40], :],\n",
    "                    versicolor[I2[:40], :],\n",
    "                    virginica[I3[:40], :]]).T\n",
    "# add contant feature one\n",
    "Xtrain = np.vstack([np.ones(120), Xtrain])\n",
    "print(Xtrain.shape)  # (number of features, number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "# the true labels for train set are a sequence of 1s, 2s and 3s\n",
    "# since the examples in Xtrain are stacked in order\n",
    "ytrain = np.hstack([np.ones(40), 2*np.ones(40), 3*np.ones(40)])\n",
    "print(ytrain.shape)  # number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set is remaining 10 examples for each class\n",
    "Xtest = np.vstack([setosa[I1[40:], :],\n",
    "                   versicolor[I2[40:], :],\n",
    "                   virginica[I3[40:], :]]).T\n",
    "Xtest = np.vstack([np.ones(30), Xtest])\n",
    "ytest = np.hstack([np.ones(10), 2*np.ones(10), 3*np.ones(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 2 3 2 2 3 3\n",
      " 3 2 3 2 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 2 3 3 3 2 3 3\n",
      " 3 3 3 3 2 3 2 3 3]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "Theta, yhat = ls_multiclass(Xtrain, ytrain, 3)\n",
    "print(yhat)\n",
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.  0.  0.]\n",
      " [ 0. 30. 10.]\n",
      " [ 0.  6. 34.]]\n"
     ]
    }
   ],
   "source": [
    "Ctrain = confusion_matrix(ytrain, yhat, 3)\n",
    "print(Ctrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "error_train = error_rate(ytrain, yhat)\n",
    "print(error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 3 3 2 2 3 2 3 3 3 3 3 2 3 2]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3.]\n",
      "[[10.  0.  0.]\n",
      " [ 0.  8.  2.]\n",
      " [ 0.  3.  7.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = row_argmax(Xtest.T @ Theta) + 1\n",
    "print(yhat)\n",
    "print(ytest)\n",
    "Ctest = confusion_matrix(ytest, yhat, 3)\n",
    "print(Ctest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "error_test = error_rate(ytest, yhat)\n",
    "print(error_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
